{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AirBNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1bd336969ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('SF_large.csv')\n",
    "print(f\"The dataset contains {len(raw_df)} Airbnb listings\")\n",
    "pd.set_option('display.max_columns', len(raw_df.columns)) # To view all columns\n",
    "pd.set_option('display.max_rows', 100)\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['listing_url', 'scrape_id', 'last_scraped', 'name', 'summary', 'space', 'description', \n",
    "                'neighborhood_overview', 'notes', 'transit', 'access', 'interaction', 'house_rules', 'thumbnail_url', \n",
    "                'medium_url', 'picture_url', 'xl_picture_url', 'host_id', 'host_url', 'host_name', 'host_location', \n",
    "                'host_about', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_verifications', \n",
    "                'calendar_last_scraped']\n",
    "df = raw_df.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['host_acceptance_rate', 'neighbourhood_group_cleansed', 'square_feet', 'weekly_price', 'monthly_price', \n",
    "         'license', 'jurisdiction_names'], axis=1, inplace=True)\n",
    "\n",
    "df.set_index('id', inplace=True) # The id will be used as the index, as this could be useful in future e.g. \n",
    "#if a separate dataset containing reviews for each property is linked to this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum((df.host_listings_count == df.host_total_listings_count) == False))\n",
    "df.loc[((df.host_listings_count == df.host_total_listings_count) == False)][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['host_total_listings_count', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "         'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms'], \n",
    "        axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long = df[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['zipcode', 'latitude', 'longitude', 'street', 'neighbourhood', 'city', 'state', 'market', \n",
    "         'smart_location', 'country_code', 'country', 'is_location_exact'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((df.minimum_nights == df.minimum_minimum_nights) == False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', \n",
    "         'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing columns with f/t with 0/1\n",
    "df.replace({'f': 0, 't': 1}, inplace=True)\n",
    "\n",
    "# Plotting the distribution of numerical and boolean categories\n",
    "df.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['has_availability', 'host_has_profile_pic', 'is_business_travel_ready', 'require_guest_phone_verification', \n",
    "         'require_guest_profile_picture', 'requires_license'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.experiences_offered.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('experiences_offered', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to datetime\n",
    "df.host_since = pd.to_datetime(df.host_since) \n",
    "\n",
    "# Calculating the number of days\n",
    "df['host_days_active'] = (datetime(2019, 4, 9) - df.host_since).astype('timedelta64[D]')\n",
    "\n",
    "# Printing mean and median\n",
    "print(\"Mean days as host:\", round(df['host_days_active'].mean(),0))\n",
    "print(\"Median days as host:\", df['host_days_active'].median())\n",
    "\n",
    "# Replacing null values with the median\n",
    "df.host_days_active.fillna(df.host_days_active.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null values:\", df.host_response_time.isna().sum())\n",
    "print(f\"Proportion: {round((df.host_response_time.isna().sum()/len(df))*100, 1)}%\")\n",
    "\n",
    "# Number of rows without a value for host_response_time which have also not yet had a review\n",
    "len(df[df.loc[ :,['host_response_time ', 'first_review'] ].isnull().sum(axis=1) == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.host_response_time.fillna(\"unknown\", inplace=True)\n",
    "df.host_response_time.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null values:\", df.host_response_rate.isna().sum())\n",
    "print(f\"Proportion: {round((df.host_response_rate.isna().sum()/len(df))*100, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing the % sign from the host_response_rate string and converting to an integer\n",
    "df.host_response_rate = df.host_response_rate.str[:-1].astype('float64')\n",
    "\n",
    "print(\"Mean host response rate:\", round(df['host_response_rate'].mean(),0))\n",
    "print(\"Median host response rate:\", df['host_response_rate'].median())\n",
    "print(f\"Proportion of 100% host response rates: {round(((df.host_response_rate == 100.0).sum()/df.host_response_rate.count())*100,1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bin into four categories\n",
    "df.host_response_rate = pd.cut(df.host_response_rate, bins=[0, 50, 90, 99, 100], labels=['0-49%', '50-89%', '90-99%', '100%'], include_lowest=True)\n",
    "\n",
    "# Converting to string\n",
    "df.host_response_rate = df.host_response_rate.astype('str')\n",
    "\n",
    "# Replace nulls with 'unknown'\n",
    "df.host_response_rate.replace('nan', 'unknown', inplace=True)\n",
    "\n",
    "# Category counts\n",
    "df.host_response_rate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows without a value for multiple host-related columns\n",
    "len(df[df.loc[ :,['host_since ', 'host_is_superhost', 'host_listings_count',\n",
    "                  'host_has_profile_pic', 'host_identity_verified'] ].isnull().sum(axis=1) == 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['host_since'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.property_type.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.property_type.replace({\n",
    "    'Townhouse': 'House',\n",
    "    'Serviced apartment': 'Apartment',\n",
    "    'Loft': 'Apartment',\n",
    "    'Bungalow': 'House',\n",
    "    'Cottage': 'House',\n",
    "    'Villa': 'House',\n",
    "    'Tiny house': 'House',\n",
    "    'Earth house': 'House',\n",
    "    'Chalet': 'House'  \n",
    "    }, inplace=True)\n",
    "\n",
    "# Replacing other categories with 'other'\n",
    "df.loc[~df.property_type.isin(['House', 'Apartment']), 'property_type'] = 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['bathrooms', 'bedrooms', 'beds']:\n",
    "    df[col].fillna(df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bed_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('bed_type', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of amenities listed\n",
    "df.amenities[:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a set of all possible amenities\n",
    "amenities_list = list(df.amenities)\n",
    "amenities_list_string = \" \".join(amenities_list)\n",
    "amenities_list_string = amenities_list_string.replace('{', '')\n",
    "amenities_list_string = amenities_list_string.replace('}', ',')\n",
    "amenities_list_string = amenities_list_string.replace('\"', '')\n",
    "amenities_set = [x.strip() for x in amenities_list_string.split(',')]\n",
    "amenities_set = set(amenities_set)\n",
    "amenities_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['amenities'].str.contains('Air conditioning|Central air conditioning'), 'air_conditioning'] = 1\n",
    "df.loc[df['amenities'].str.contains('Amazon Echo|Apple TV|Game console|Netflix|Projector and screen|Smart TV'), 'high_end_electronics'] = 1\n",
    "df.loc[df['amenities'].str.contains('BBQ grill|Fire pit|Propane barbeque'), 'bbq'] = 1\n",
    "df.loc[df['amenities'].str.contains('Balcony|Patio'), 'balcony'] = 1\n",
    "df.loc[df['amenities'].str.contains('Beach view|Beachfront|Lake access|Mountain view|Ski-in/Ski-out|Waterfront'), 'nature_and_views'] = 1\n",
    "df.loc[df['amenities'].str.contains('Bed linens'), 'bed_linen'] = 1\n",
    "df.loc[df['amenities'].str.contains('Breakfast'), 'breakfast'] = 1\n",
    "df.loc[df['amenities'].str.contains('TV'), 'tv'] = 1\n",
    "df.loc[df['amenities'].str.contains('Coffee maker|Espresso machine'), 'coffee_machine'] = 1\n",
    "df.loc[df['amenities'].str.contains('Cooking basics'), 'cooking_basics'] = 1\n",
    "df.loc[df['amenities'].str.contains('Dishwasher|Dryer|Washer'), 'white_goods'] = 1\n",
    "df.loc[df['amenities'].str.contains('Elevator'), 'elevator'] = 1\n",
    "df.loc[df['amenities'].str.contains('Exercise equipment|Gym|gym'), 'gym'] = 1\n",
    "df.loc[df['amenities'].str.contains('Family/kid friendly|Children|children'), 'child_friendly'] = 1\n",
    "df.loc[df['amenities'].str.contains('parking'), 'parking'] = 1\n",
    "df.loc[df['amenities'].str.contains('Garden|Outdoor|Sun loungers|Terrace'), 'outdoor_space'] = 1\n",
    "df.loc[df['amenities'].str.contains('Host greets you'), 'host_greeting'] = 1\n",
    "df.loc[df['amenities'].str.contains('Hot tub|Jetted tub|hot tub|Sauna|Pool|pool'), 'hot_tub_sauna_or_pool'] = 1\n",
    "df.loc[df['amenities'].str.contains('Internet|Pocket wifi|Wifi'), 'internet'] = 1\n",
    "df.loc[df['amenities'].str.contains('Long term stays allowed'), 'long_term_stays'] = 1\n",
    "df.loc[df['amenities'].str.contains('Pets|pet|Cat(s)|Dog(s)'), 'pets_allowed'] = 1\n",
    "df.loc[df['amenities'].str.contains('Private entrance'), 'private_entrance'] = 1\n",
    "df.loc[df['amenities'].str.contains('Safe|Security system'), 'secure'] = 1\n",
    "df.loc[df['amenities'].str.contains('Self check-in'), 'self_check_in'] = 1\n",
    "df.loc[df['amenities'].str.contains('Smoking allowed'), 'smoking_allowed'] = 1\n",
    "df.loc[df['amenities'].str.contains('Step-free access|Wheelchair|Accessible'), 'accessible'] = 1\n",
    "df.loc[df['amenities'].str.contains('Suitable for events'), 'event_suitable'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing nulls with zeros for new columns\n",
    "cols_to_replace_nulls = df.iloc[:,41:].columns\n",
    "df[cols_to_replace_nulls] = df[cols_to_replace_nulls].fillna(0)\n",
    "\n",
    "# Produces a list of amenity features where one category (true or false) contains fewer than 10% of listings\n",
    "infrequent_amenities = []\n",
    "for col in df.iloc[:,41:].columns:\n",
    "    if df[col].sum() < len(df)/10:\n",
    "        infrequent_amenities.append(col)\n",
    "print(infrequent_amenities)\n",
    "\n",
    "# Dropping infrequent amenity features\n",
    "df.drop(infrequent_amenities, axis=1, inplace=True)\n",
    "\n",
    "# Dropping the original amenity feature\n",
    "df.drop('amenities', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price = df.price.str[1:-3]\n",
    "df.price = df.price.str.replace(\",\", \"\")\n",
    "df.price = df.price.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.security_deposit.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.security_deposit = df.security_deposit.str[1:-3]\n",
    "df.security_deposit = df.security_deposit.str.replace(\",\", \"\")\n",
    "df.security_deposit.fillna(0, inplace=True)\n",
    "df.security_deposit = df.security_deposit.astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cleaning_fee.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cleaning_fee = df.cleaning_fee.str[1:-3]\n",
    "df.cleaning_fee = df.cleaning_fee.str.replace(\",\", \"\")\n",
    "df.cleaning_fee.fillna(0, inplace=True)\n",
    "df.cleaning_fee = df.cleaning_fee.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extra_people = df.extra_people.str[1:-3]\n",
    "df.extra_people = df.extra_people.str.replace(\",\", \"\")\n",
    "df.extra_people.fillna(0, inplace=True)\n",
    "df.extra_people = df.extra_people.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of categories:\", df.calendar_updated.nunique())\n",
    "print(\"\\nTop five categories:\")\n",
    "df.calendar_updated.value_counts()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('calendar_updated', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['availability_30', 'availability_60', 'availability_365'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Null values in 'first_review': {round(100*df.first_review.isna().sum()/len(df),1)}%\")\n",
    "print(f\"Null values in 'review_scores_rating': {round(100*df.review_scores_rating .isna().sum()/len(df),1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.first_review = pd.to_datetime(df.first_review) # Converting to datetime\n",
    "\n",
    "# Calculating the number of days between the first review and the date the data was scraped\n",
    "df['time_since_first_review'] = (datetime(2019, 4, 9) - df.first_review).astype('timedelta64[D]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_column(col, bins, labels, na_label='unknown'):\n",
    "    \"\"\"\n",
    "    Takes in a column name, bin cut points and labels, replaces the original column with a\n",
    "    binned version, and replaces nulls (with 'unknown' if unspecified).\n",
    "    \"\"\"\n",
    "    df[col] = pd.cut(df[col], bins=bins, labels=labels, include_lowest=True)\n",
    "    df[col] = df[col].astype('str')\n",
    "    df[col].fillna(na_label, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning time since first review\n",
    "bin_column('time_since_first_review',\n",
    "           bins=[0, 182, 365, 730, 1460, max(df.time_since_first_review)],\n",
    "           labels=['0-6 months',\n",
    "                   '6-12 months',\n",
    "                   '1-2 years',\n",
    "                   '2-3 years',\n",
    "                   '4+ years'],\n",
    "           na_label='no reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.last_review = pd.to_datetime(df.last_review) # Converting to datetime\n",
    "\n",
    "# Calculating the number of days between the most recent review and the date the data was scraped\n",
    "df['time_since_last_review'] = (datetime(2019, 4, 9) - df.last_review).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning time since last review\n",
    "bin_column('time_since_last_review',\n",
    "           bins=[0, 14, 60, 182, 365, max(df.time_since_last_review)],\n",
    "           labels=['0-2 weeks',\n",
    "                   '2-8 weeks',\n",
    "                   '2-6 months',\n",
    "                   '6-12 months',\n",
    "                   '1+ year'],\n",
    "           na_label='no reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping last_review - first_review will be kept for EDA and dropped later\n",
    "df.drop('last_review', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distributions of the review ratings columns\n",
    "variables_to_plot = list(df.columns[df.columns.str.startswith(\"review_scores\") == True])\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "for i, var_name in enumerate(variables_to_plot):\n",
    "    ax = fig.add_subplot(3,3,i+1)\n",
    "    df[var_name].hist(bins=10,ax=ax)\n",
    "    ax.set_title(var_name)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all review columns that are scored out of 10\n",
    "variables_to_plot.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning for all columns scored out of 10\n",
    "for col in variables_to_plot:\n",
    "    bin_column(col,\n",
    "               bins=[0, 8, 9, 10],\n",
    "               labels=['0-8/10', '9/10', '10/10'],\n",
    "               na_label='no reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning column scored out of 100\n",
    "bin_column('review_scores_rating',\n",
    "           bins=[0, 80, 95, 100],\n",
    "           labels=['0-79/100', '80-94/100', '95-100/100'],\n",
    "           na_label='no reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cancellation_policy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing categories\n",
    "df.cancellation_policy.replace({\n",
    "    'super_strict_30': 'strict_14_with_grace_period',\n",
    "    'super_strict_60': 'strict_14_with_grace_period',\n",
    "    'strict': 'strict_14_with_grace_period',\n",
    "    'luxury_moderate': 'moderate'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['number_of_reviews_ltm', 'reviews_per_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping host_since and first_review as they are no longer needed\n",
    "df.drop(['host_since', 'first_review'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nightly advertised prices range from ${min(df.price)} to ${max(df.price)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing values under $10 with $10\n",
    "df.loc[df.price <= 10, 'price'] = 10\n",
    "\n",
    "# Replacing values over $1000 with $1000\n",
    "df.loc[df.price >= 1000, 'price'] = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the neighbourhood column\n",
    "df.rename(columns={'neighbourhood_cleansed': 'neighbourhood'}, inplace=True)\n",
    "\n",
    "# Importing the SF neighbourhood boundary GeoJSON file as a dataframe in geopandas\n",
    "map_df = gpd.read_file('sfneighbourhoods.geojson')\n",
    "map_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the empty column\n",
    "map_df.drop('neighbourhood_group', axis=1, inplace=True)\n",
    "\n",
    "# Creating a dataframe of listing counts and median price by neighbourhood\n",
    "neighbourhood_df = pd.DataFrame(df.groupby('neighbourhood').size())\n",
    "neighbourhood_df.rename(columns={0: 'number_of_listings'}, inplace=True)\n",
    "neighbourhood_df['median_price'] = df.groupby('neighbourhood').price.median().values\n",
    "\n",
    "# Joining the dataframes\n",
    "neighbourhood_map_df = map_df.set_index('neighbourhood').join(neighbourhood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the number of listings in each neighbourhood\n",
    "fig1, ax1 = plt.subplots(1, figsize=(15, 6))\n",
    "neighbourhood_map_df.plot(column='number_of_listings', cmap='Blues', ax=ax1)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Number of Airbnb listings in each SF neighborhood', fontsize=14)\n",
    "sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=0, vmax=9000))\n",
    "sm._A = [] # Creates an empty array for the data range\n",
    "cbar = fig1.colorbar(sm)\n",
    "plt.show()\n",
    "plt.savefig('#listings.png')\n",
    "# Plotting the median price of listings in each borough\n",
    "fig2, ax2 = plt.subplots(1, figsize=(15, 6))\n",
    "neighbourhood_map_df.plot(column='median_price', cmap='Blues', ax=ax2)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Median price of Airbnb listings in each SF neighborhood', fontsize=14)\n",
    "sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=min(neighbourhood_map_df.median_price), vmax=max(neighbourhood_map_df.median_price)))\n",
    "sm._A = [] # Creates an empty array for the data range\n",
    "cbar = fig2.colorbar(sm)\n",
    "plt.show()\n",
    "plt.savefig('medianprice.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_collinearity_heatmap(df, figsize=(11,9)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a heatmap of correlations between features in the df. A figure size can optionally be set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the style of the visualization\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Create a covariance matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask the size of our covariance matrix\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmax=corr[corr != 1.0].max().max());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_collinearity_heatmap(transformed_df, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_collinearity_heatmap(transformed_df.drop(list(transformed_df.columns[transformed_df.columns.str.startswith('borough')]), axis=1), figsize=(25,22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping collinear features\n",
    "to_drop = ['beds',\n",
    "           'bedrooms',\n",
    "           'guests_included', \n",
    "           'host_response_rate_unknown',\n",
    "           'host_response_rate_0-49%',\n",
    "           'property_type_Apartment',\n",
    "           'room_type_Private room']\n",
    "to_drop.extend(list(transformed_df.columns[transformed_df.columns.str.endswith('nan')]))\n",
    "\n",
    "transformed_df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final assessment of multi-collinearity\n",
    "multi_collinearity_heatmap(transformed_df.drop(list(transformed_df.columns[transformed_df.columns.str.startswith('borough')]), axis=1), figsize=(25,22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['accommodates', 'availability_90', 'bathrooms', 'cleaning_fee', 'extra_people', 'host_days_active', 'host_listings_count', 'maximum_nights', 'minimum_nights', 'number_of_reviews', 'price', 'security_deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df[numerical_columns].hist(figsize=(10,11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transforming columns\n",
    "numerical_columns = [i for i in numerical_columns if i not in ['availability_90', 'host_days_active']] # Removing items not to be transformed\n",
    "\n",
    "for col in numerical_columns:\n",
    "    transformed_df[col] = transformed_df[col].astype('float64').replace(0.0, 0.01) # Replacing 0s with 0.01\n",
    "    transformed_df[col] = np.log(transformed_df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df[numerical_columns].hist(figsize=(10,11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating X and y\n",
    "X = transformed_df.drop('price', axis=1)\n",
    "y = transformed_df.price\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg_start = time.time()\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(max_depth = 4, n_estimators = 100)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "training_preds_xgb_reg = xgb_reg.predict(X_train)\n",
    "val_preds_xgb_reg = xgb_reg.predict(X_test)\n",
    "\n",
    "xgb_reg_end = time.time()\n",
    "\n",
    "print(f\"Time taken to run: {round((xgb_reg_end - xgb_reg_start)/60,1)} minutes\")\n",
    "print(\"\\nTraining MSE:\", round(mean_squared_error(y_train, training_preds_xgb_reg),4))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test, val_preds_xgb_reg),4))\n",
    "print(\"\\nTraining r2:\", round(r2_score(y_train, training_preds_xgb_reg),4))\n",
    "print(\"Validation r2:\", round(r2_score(y_test, val_preds_xgb_reg),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "\n",
    "### END SOLUTION \n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "lasso = Lasso(alpha=.01).fit(X_train, y_train)\n",
    "\n",
    "predictions = lasso.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "r2 = lasso.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train.columns)\n",
    "ft_weights_xgb_reg.sort_values('weight', inplace=True)\n",
    "ft_weights_xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances\n",
    "plt.figure(figsize=(8,20))\n",
    "plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
    "plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.margins(y=0.01)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
